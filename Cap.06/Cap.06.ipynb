{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy Morphology Classification Project\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this session, you will learn:-**\n",
    "* How to do image preprocessing\n",
    "* How to build CNN models\n",
    "* How to train and validate them\n",
    "\n",
    "**The main focus:-**\n",
    "* It should not be on the steps but the process\n",
    "* As steps will change from dataset to dataset, but the process will remain the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT NOTE\n",
    "* RUN THIS NOTEBOOK ON KAGGLE SO YOU DONT NEED TO DOWNLOAD THE DATASET\n",
    "* Don't forget to turn on the GPU before you connect the runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the dataset\n",
    "* input -> from kaggle -> search for galaxy zoo -> add (this option only works if you account is validated with cellphone number check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To begin with import most necessary dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get the Dataset\n",
    "\n",
    "* Make an empty directory and name it as `galaxy_zoo_dataset`\n",
    "* Unzip all the useful data files in that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a new directory to save the useful data for this project\n",
    "os.mkdir('galaxy_zoo_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Unzip the csv file \n",
    "!unzip /kaggle/input/galaxy-zoo-the-galaxy-challenge/training_solutions_rev1.zip -d /kaggle/working/galaxy_zoo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Unzip the directory of training images\n",
    "!unzip /kaggle/input/galaxy-zoo-the-galaxy-challenge/images_training_rev1.zip -d /kaggle/working/galaxy_zoo_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have successfully unziped the training images and csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read the csv file and split the data into train-test\n",
    "* For the demonstration purposes, I will take a subset of the dataset\n",
    "* To complete the project you may need more images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check the csv file\n",
    "csv_data_path = '/kaggle/working/galaxy_zoo_dataset/training_solutions_rev1.csv'\n",
    "df = pd.read_csv(csv_data_path)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GalaxyID is the ID of the image of the galaxy in the dataset\n",
    "* Rest of the columns are the probabilitites of the respective morphologies\n",
    "* These morphologies are like shape of galaxy, about the galactic core, e.t.c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check the generic info of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Thank God! Tere are no missing values.\n",
    "* GalaxyID is alone in integer format, and rest of the data is float type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Take only first 2000 data instances for demonstration\n",
    "df_minimum = df[:2000]\n",
    "df_minimum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have taken 2000 rows of data as sample data for training.\n",
    "* Please note that, you will need more dataset to get better RMSE score.\n",
    "* Now, we shall use this 2000 rows of data and split it further into train-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get the train_test_split from sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create two dfs - one for trian, another for test with test size as 15%\n",
    "df_train, df_test = train_test_split(df_minimum, test_size=.15, shuffle = True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check before proceeding ahead\n",
    "print(f'Shape of Train Data Frame:- {df_train.shape}')\n",
    "print(f'Shape of Test Data Frame:- {df_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So now we have training and testing set splitted for us!\n",
    "* What's next?? Well, let's visualize some images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:- Visualizing RANDOM images from the dataset\n",
    "1. Create the path for training image directory and call it as `root_dir`\n",
    "2. Get the list of ids of images present in the `root_dir` and call it `ids_jpg`\n",
    "3. Using `np.random.choice()` randomly choose one id from `ids_jpg` list\n",
    "4. Now create the complete image path for visualization purposes\n",
    "5. Read the image and display it\n",
    "6. Add title with galaxy id and shape of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Coding all the above points for step 3\n",
    "root_dir = \"/kaggle/working/galaxy_zoo_dataset/images_training_rev1/\" # Root Path of Dir where training images are saved\n",
    "ids_jpg = os.listdir(root_dir)   # List of files in the directory (eg. 10001.jpg)\n",
    "id_ = np.random.choice(ids_jpg)  # Randomly choose one item from the list above\n",
    "img_path = root_dir + id_      # Complete image path\n",
    "random_image = plt.imread(img_path) # Get image pixels array\n",
    "plt.imshow(random_image) # Display the image\n",
    "plt.title(f'Galaxy ID:- {id_[:-4]}\\nShape:- {random_image.shape}', \n",
    "          color = 'tab:pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Everytime you will run the above code cell, it will randomly give you different images from the dataset.\n",
    "* What do you notice here? Can we crop some part of images?\n",
    "* Yes! WE CAN... as our region of interest is exactly in the center of the image.\n",
    "* How will we crop??? Let's check it in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Preprocessing Images\n",
    "* It is always important to preprocess images before passing it to the model\n",
    "* It should help the model to train faster\n",
    "* How? Well, that's what we have to think..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Steps for one image:-**\n",
    "1. Create a function that will crop the center part of the image\n",
    "2. Firstly, read the image\n",
    "3. Then choose from where to begin the croping and also the crop size\n",
    "4. You may further resize the image to much smaller size\n",
    "5. The final step will be to normalize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read the image path from step 3\n",
    "img_array = plt.imread(img_path)\n",
    "plt.imshow(img_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Crop from (84, 84) and choose crop size as (256, 256)\n",
    "START_FROM = (84, 84)\n",
    "CROP_SIZE = (256, 256)\n",
    "cropped_img = img_array[START_FROM[0]:START_FROM[0]+CROP_SIZE[0],\n",
    "                        START_FROM[1]:START_FROM[0]+CROP_SIZE[1]]\n",
    "\n",
    "# Check the output\n",
    "plt.imshow(cropped_img)\n",
    "plt.title(f'Shape:- {cropped_img.shape}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check the max-min pixels of the cropped_img\n",
    "print(f'Maximum Pixel of Cropped Image:- {cropped_img.max()}')\n",
    "print(f'Minimum Pixel of Cropped Image:- {cropped_img.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Let's resize using skimage\n",
    "from skimage.transform import resize\n",
    "resized_img = resize(cropped_img, (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check the max-min pixels of the resized_img\n",
    "print(f'Maximum Pixel of Cropped Image:- {resized_img.max()}')\n",
    "print(f'Minimum Pixel of Cropped Image:- {resized_img.min()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we can see that by default the ouput is in between 0 to 1, we don't need normalization.\n",
    "* But wait... Why is it in between 0 to 1? For that check the latest activity in your slack.\n",
    "* Now just create a function that does this preprocessing on any image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_image(path, x1, y1, resize_shape, crop_size):  \n",
    "    \"\"\"\n",
    "    Get the preprocessing for single galaxy image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: Image Path for the image on which you want to apply image processing\n",
    "    x1: Start pixel for rows to begin the cropping\n",
    "    y1: Start pixel for cols to begin the cropping\n",
    "    resize_shape: The final shape of the image\n",
    "    crop_size: Image will be cropped from start pixels to the crop size\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    preprocessed_img: Centered image of the galaxy\n",
    "    \n",
    "    \"\"\"\n",
    "    img_array = plt.imread(path)                       \n",
    "    crop_img = img_array[x1:x1+crop_size[0], y1:y1+crop_size[1]] \n",
    "    preprocessed_img = resize(crop_img, resize_shape)                   \n",
    "    return preprocessed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The function is ready! Now it is time to test it.\n",
    "* Create a code cell that will generate a side-by-side subplot to compare original and preprocessed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get random image path\n",
    "id_ = np.random.choice(ids_jpg) \n",
    "img_path = root_dir + id_      \n",
    "org_img = plt.imread(img_path)\n",
    "\n",
    "# Preprocess it\n",
    "x_data = get_image(img_path, 84, 84, (64,64), (256, 256))\n",
    "\n",
    "# Display before after images\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.suptitle(f'Galaxy ID:- {id_[:-4]}')\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(org_img)\n",
    "plt.title(f'Original Image Shape:-\\n{org_img.shape}', color = 'tab:pink')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(x_data)\n",
    "plt.title(f'Re-Shaped into:-\\n{x_data.shape}', color = 'tab:pink')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now that, we have this for one image, how about preprocessing all the images in our data?\n",
    "* For that create another function to prepare batches of the images according to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To check the progress of the loop we will need a library called as tqdm\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Image Data\n",
    "ORG_SHAPE = (424,424)\n",
    "CROP_SIZE = (256,256)\n",
    "RESIZE_SHAPE = (64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_all_images(dataframe, resize_shape=RESIZE_SHAPE, crop_size=CROP_SIZE):\n",
    "    \"\"\"\n",
    "    Use dataframe to get image ids and preprocess all of them using get_image function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Data frame should have first column for galaxy ids\n",
    "    resize_shape: Image to be resized into this shape\n",
    "    crop_size: Crop size for the image before resizing\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    x_batch: Array of batch of images (batch_size, Height, Width, Channels)\n",
    "    y_batch: Array of respective probabilities for image (batch_size, Cols) \n",
    "    \"\"\"\n",
    "\n",
    "    # Get the centre of the image where region of interest is present\n",
    "    x1 = (ORG_SHAPE[0]-CROP_SIZE[0])//2       # (424-256)//2 = 84\n",
    "    y1 = (ORG_SHAPE[1]-CROP_SIZE[1])//2       # (424-256)//2 = 84\n",
    "\n",
    "    # Form x and y batches\n",
    "    sel = dataframe.values                     # dataftame values in array\n",
    "    ids = sel[:,0].astype(int).astype(str)     # Get Galaxy ID in string\n",
    "    y_batch = sel[:,1:]                        # Get All feature values except first column (Galaxy ID)\n",
    "    x_batch = []                               # Define X_batch\n",
    "    for i in tqdm(ids):\n",
    "        x = get_image(root_dir + i + '.jpg', x1, y1, resize_shape=resize_shape, crop_size=crop_size)\n",
    "        # Calling Get Image by giving set of arguments\n",
    "        x_batch.append(x) # append the cropped and resized image x into x_batch\n",
    "    x_batch = np.array(x_batch)    # convert x_batch each images into numby array\n",
    "\n",
    "    # Return the batches\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Apply the function to get X_train, y_train, X_test, y_test\n",
    "X_train, y_train = get_all_images(df_train)\n",
    "X_test, y_test = get_all_images(df_test)      # Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check the shapes for training set\n",
    "print('X_train Shape:- ')\n",
    "print(X_train.shape)\n",
    "\n",
    "print('\\ny_train Shape:- ')\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check the shapes for testing set\n",
    "print('X_test Shape:- ')\n",
    "print(X_test.shape)\n",
    "\n",
    "print('\\ny_test Shape:- ')\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Build the CNN Model \n",
    "* We shall use Keras API to build the model\n",
    "* The aim of the model is to accept the image of some size and get 37 different outputs between 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Important imports for building the CNN model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import keras\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initiate the Model --> Sequential API\n",
    "* Allow us to add layers in sequence\n",
    "* For now, we will have this architecture:- `Input Layer` -> `Conv` -> `Conv` -> `Max Pool` -> `Flatten` -> `Dense` --> `Dropout` ->  `Dense (output)`\n",
    "* Later, you can modify it according to your preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create the Sequential Model\n",
    "model = Sequential()\n",
    "\n",
    "# Build the model with Inputs, 2 Conv, 1 MaxPool followed by Flatten, Dense, Droput and Output\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', input_shape=(64, 64, 3))\n",
    "model.add(Conv2D(256, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Flatten())                      \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.8)) # to reduce the over fitting problem\n",
    "model.add(Dense(37,activation='sigmoid')) \n",
    "\n",
    "# Check the summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here, you can calculate the ouptut shape of the Conv2D layer using `o = (i - f + 2p)/s + 1`\n",
    "* You can calculate the parameters of Conv2D layer using `params = (filter_size^2 * filter_channels)*total_filters +  total_filters`\n",
    "* Example for first conv2d layer ~\n",
    "    * `output shape`:- `(64 - 3 + 2*0)/1 + 1` = `62`\n",
    "    * `params`:- `3^2 * 3 * 512 + 512` = `14,336`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Compile the model\n",
    "* Compile the model using loss, metrics and optimizer\n",
    "* We are choosing:-\n",
    "    * Loss:- MSE\n",
    "    * Optimizer:- Adam\n",
    "    * Metric:- RMSE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a function to calculate RMSE from the outputs\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "              metrics=[root_mean_squared_error])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can change the loss and optimizer to check how it performs\n",
    "* Don't forget to tune the optimizer's hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the model and validate it\n",
    "* Make sure to turn on the GPU or else one epoch may take approx 10 mins\n",
    "* With GPU it should take approx 5-10 seconds per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1700 --> Batches --> Batch_size = 32 ---> 53.125 batches ---> 53 or 54\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          epochs=50, \n",
    "          validation_data=(X_test, y_test), \n",
    "          batch_size=32) # default bs = 32 if None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is our test outputs\n",
    "y_test_df = pd.DataFrame(y_test, columns = list(df_minimum.columns[1:]))\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get the prediction outputs\n",
    "pred_test = np.array(model.predict(X_test))\n",
    "pred_test_df = pd.DataFrame(pred_test, columns = list(df_minimum.columns[1:]))\n",
    "pred_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print the RMSE on the test/val data\n",
    "print(np.array(root_mean_squared_error(y_test_df.values, pred_test_df.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to get better score?**\n",
    "1. You can use more samples in training\n",
    "2. You can adjust your image processing pipeline\n",
    "3. You can change your model architecture\n",
    "4. You can change loss and optimizer or tune the hyperparameters of the Adam\n",
    "5. Increase/Decrease the number of epochs\n",
    "6. You can change the batch size during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your next assignment\n",
    "* It is based on this project\n",
    "* More information on it will be shared later"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 44352,
     "sourceId": 3175,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
